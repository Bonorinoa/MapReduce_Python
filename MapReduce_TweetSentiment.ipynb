{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MapReduce_TweetSentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bonorinoa/MapReduce_Python/blob/main/MapReduce_TweetSentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GPIiRYHePmxs"
      },
      "outputs": [],
      "source": [
        "!rm -f hadoop-3.3.2.tar.gz*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://downloads.apache.org/hadoop/common/hadoop-3.3.2/hadoop-3.3.2.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5Hdt7fQPtbh",
        "outputId": "2450724a-82cd-4568-fb94-ce2acf6531ba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-29 14:06:07--  https://downloads.apache.org/hadoop/common/hadoop-3.3.2/hadoop-3.3.2.tar.gz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 88.99.95.219, 135.181.214.104, 2a01:4f8:10a:201a::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|88.99.95.219|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 638660563 (609M) [application/x-gzip]\n",
            "Saving to: ‘hadoop-3.3.2.tar.gz’\n",
            "\n",
            "hadoop-3.3.2.tar.gz 100%[===================>] 609.07M  19.1MB/s    in 34s     \n",
            "\n",
            "2022-04-29 14:06:41 (18.1 MB/s) - ‘hadoop-3.3.2.tar.gz’ saved [638660563/638660563]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzf hadoop-3.3.2.tar.gz"
      ],
      "metadata": {
        "id": "Mjg9gVsATdEK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#copy  hadoop file to user/local\n",
        "!cp -r hadoop-3.3.2/ /usr/local/"
      ],
      "metadata": {
        "id": "mBQe-eZupWZP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To find the default Java path\n",
        "!readlink -f /usr/bin/java | sed \"s:bin/java::\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiPPQ0EyPxF2",
        "outputId": "24516fa4-dab0-4faf-d611-8141b6449af6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/jvm/java-11-openjdk-amd64/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To set the java path, go to /usr/local/hadoop-3.3.2/etc/hadoop/hadoop-env.sh then\n",
        "\n",
        "* Look for the line `export JAVA_HOME=`\n",
        "* Replace it with `export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64/`\n",
        "* Remove the comments (the notebook will automatically save the shell script)"
      ],
      "metadata": {
        "id": "UrpjVBfYPy60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chek if Hadoop was correctly installed\n",
        "!/usr/local/hadoop-3.3.2/bin/hadoop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaiKcOVNPw_k",
        "outputId": "b35c1f55-1b01-4de4-9851-3ca163e5d902"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage: hadoop [OPTIONS] SUBCOMMAND [SUBCOMMAND OPTIONS]\n",
            " or    hadoop [OPTIONS] CLASSNAME [CLASSNAME OPTIONS]\n",
            "  where CLASSNAME is a user-provided Java class\n",
            "\n",
            "  OPTIONS is none or any of:\n",
            "\n",
            "buildpaths                       attempt to add class files from build tree\n",
            "--config dir                     Hadoop config directory\n",
            "--debug                          turn on shell script debug mode\n",
            "--help                           usage information\n",
            "hostnames list[,of,host,names]   hosts to use in slave mode\n",
            "hosts filename                   list of hosts to use in slave mode\n",
            "loglevel level                   set the log4j level for this command\n",
            "workers                          turn on worker mode\n",
            "\n",
            "  SUBCOMMAND is one of:\n",
            "\n",
            "\n",
            "    Admin Commands:\n",
            "\n",
            "daemonlog     get/set the log level for each daemon\n",
            "\n",
            "    Client Commands:\n",
            "\n",
            "archive       create a Hadoop archive\n",
            "checknative   check native Hadoop and compression libraries availability\n",
            "classpath     prints the class path needed to get the Hadoop jar and the\n",
            "              required libraries\n",
            "conftest      validate configuration XML files\n",
            "credential    interact with credential providers\n",
            "distch        distributed metadata changer\n",
            "distcp        copy file or directories recursively\n",
            "dtutil        operations related to delegation tokens\n",
            "envvars       display computed Hadoop environment variables\n",
            "fs            run a generic filesystem user client\n",
            "gridmix       submit a mix of synthetic job, modeling a profiled from\n",
            "              production load\n",
            "jar <jar>     run a jar file. NOTE: please use \"yarn jar\" to launch YARN\n",
            "              applications, not this command.\n",
            "jnipath       prints the java.library.path\n",
            "kdiag         Diagnose Kerberos Problems\n",
            "kerbname      show auth_to_local principal conversion\n",
            "key           manage keys via the KeyProvider\n",
            "rumenfolder   scale a rumen input trace\n",
            "rumentrace    convert logs into a rumen trace\n",
            "s3guard       manage metadata on S3\n",
            "trace         view and modify Hadoop tracing settings\n",
            "version       print the version\n",
            "\n",
            "    Daemon Commands:\n",
            "\n",
            "kms           run KMS, the Key Management Server\n",
            "registrydns   run the registry DNS server\n",
            "\n",
            "SUBCOMMAND may print help when invoked w/o parameters or with -h.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mrjob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2DCFF3xPw9N",
        "outputId": "ef974147-5ecb-4778-ea00-4d4bbc222d21"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mrjob\n",
            "  Downloading mrjob-0.7.4-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 51 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 61 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 71 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 92 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 102 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 112 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 122 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 133 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 143 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 153 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 163 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 174 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 184 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 194 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 204 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 215 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 225 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 235 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 245 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 256 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 266 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 276 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 286 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 296 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 307 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 317 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 327 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 337 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 348 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 358 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 368 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 378 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 389 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 399 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 409 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 419 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 430 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 439 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from mrjob) (3.13)\n",
            "Installing collected packages: mrjob\n",
            "Successfully installed mrjob-0.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The goal is to compute the sentiment score of a given tweet.\n",
        "### Problem:\n",
        "\n"
      ],
      "metadata": {
        "id": "1SyDLiUVQBke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4qMWo-fXUvS",
        "outputId": "cc07379c-6c4e-41dd-e4c5-9f90550166a4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.0 MB 8.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 66.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 48.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 38.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Groceries.csv or tinyGroceries.csv\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "0jLZ9QARHHUu",
        "outputId": "7989598d-d2d3-49fd-b6ba-758a32efa751"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fccafe3b-4af1-43f8-b8b8-56da808e5fd5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fccafe3b-4af1-43f8-b8b8-56da808e5fd5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tweets.csv to Tweets.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = pd.read_csv(\"Tweets.csv\")\n",
        "tweets.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wNQDrudVVOfJ",
        "outputId": "7b496607-4324-46b9-e9e2-c0ede833fdf3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       textID                                               text  \\\n",
              "0  cb774db0d1                I`d have responded, if I were going   \n",
              "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
              "2  088c60f138                          my boss is bullying me...   \n",
              "3  9642c003ef                     what interview! leave me alone   \n",
              "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
              "\n",
              "                         selected_text sentiment  \n",
              "0  I`d have responded, if I were going   neutral  \n",
              "1                             Sooo SAD  negative  \n",
              "2                          bullying me  negative  \n",
              "3                       leave me alone  negative  \n",
              "4                        Sons of ****,  negative  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1a7480c-735f-4394-8445-ec0bf518f316\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1a7480c-735f-4394-8445-ec0bf518f316')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d1a7480c-735f-4394-8445-ec0bf518f316 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d1a7480c-735f-4394-8445-ec0bf518f316');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mini dataset for testing\n",
        "# Feel free to subset as many tweets as you like\n",
        "\n",
        "tinyTweets = tweets['text'][:50]\n",
        "tinyTweets.to_csv(\"tinyTweets.csv\")"
      ],
      "metadata": {
        "id": "YRbU8aV0YjdY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MRJob implementation of above python program"
      ],
      "metadata": {
        "id": "QB9bbOw8bNyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file tweetsSentiment.py\n",
        "#!/usr/bin/env python\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "model_name = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "class tweetSentiment(MRJob):\n",
        "  \n",
        "\n",
        "    def mapper(self, _, line):\n",
        "\n",
        "      cols = line.split(',')\n",
        "\n",
        "      word_tokens = word_tokenize(str(cols[1]))\n",
        "\n",
        "      filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "\n",
        "      filtered_sentence = []\n",
        "\n",
        "      for w in word_tokens:\n",
        "\n",
        "        if w not in stop_words:\n",
        "        \n",
        "          filtered_sentence.append(w)\n",
        "\n",
        "      yield \"\".join(filtered_sentence), 1\n",
        "\n",
        "\n",
        "    def combiner(self, word, counts):\n",
        "\n",
        "      results = classifier(word)\n",
        "      yield results[0]['label'], 1\n",
        "     \n",
        "\n",
        "    def reducer(self, word, counts):\n",
        "\n",
        "      yield word, sum(counts)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tweetSentiment.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0bqS49jPwkx",
        "outputId": "ce1712e8-daed-4a83-b477-fd002679861e"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tweetsSentiment.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change below the name of the Python/MrJob program and the file(s) used by it\n",
        "# The datafiles can have extensions (e.g. .csv, .txt)  or be without extension.\n",
        "!python tweetsSentiment.py tinyTweets.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2nlc6AvQf6E",
        "outputId": "a1db8a15-7882-424c-efb7-73653a576a9e"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Using configs in /root/.mrjob.conf\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/tweetsSentiment.root.20220429.152955.593070\n",
            "Running step 1 of 1...\n",
            "job output is in /tmp/tweetsSentiment.root.20220429.152955.593070/output\n",
            "Streaming final output from /tmp/tweetsSentiment.root.20220429.152955.593070/output...\n",
            "\"Negative\"\t11\n",
            "\"Neutral\"\t30\n",
            "\"Positive\"\t10\n",
            "Removing temp directory /tmp/tweetsSentiment.root.20220429.152955.593070...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's run it in Hadoop now (has some issues)"
      ],
      "metadata": {
        "id": "eHFMXhdGQmDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%file ~/.mrjob.conf\n",
        "# runners:\n",
        "#     hadoop:\n",
        "#       hadoop_bin: /usr/local/hadoop-3.3.2/bin/hadoop\n",
        "#       hadoop_streaming_jar: /usr/local/hadoop-3.3.2/share/hadoop/tools/lib/hadoop-streaming-3.3.2.jar\n",
        "#       hadoop_tmp_dir: file:///content/tmp/mrjob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy9fsfN2Ql4T",
        "outputId": "ef842461-3473-4a58-a710-573bc04eff9e"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /root/.mrjob.conf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change below the name of the Python/MrJob program and the file(s) used by it\n",
        "# Note that the option -r hadoop changes the execution  from local to the hadoop framework\n",
        "# !python tweetsSentiment.py -r hadoop tinyTweets.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQrQKpWAQqDX",
        "outputId": "38b3dc85-5e55-4e78-e2cc-10ac3b028a8b"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Using configs in /root/.mrjob.conf\n",
            "Using Hadoop version 3.3.2\n",
            "Creating temp directory /tmp/tweetsSentiment.root.20220429.151723.431272\n",
            "uploading working dir files to file:///content/tmp/mrjob/tweetsSentiment.root.20220429.151723.431272/files/wd...\n",
            "Copying other local files to file:///content/tmp/mrjob/tweetsSentiment.root.20220429.151723.431272/files/\n",
            "Running step 1 of 1...\n",
            "  Loaded properties from hadoop-metrics2.properties\n",
            "  Scheduled Metric snapshot period at 10 second(s).\n",
            "  JobTracker metrics system started\n",
            "  JobTracker metrics system already initialized!\n",
            "  Total input files to process : 1\n",
            "  number of splits:1\n",
            "  Submitting tokens for job: job_local16479360_0001\n",
            "  Executing with tokens: []\n",
            "  Localized file:/content/tmp/mrjob/tweetsSentiment.root.20220429.151723.431272/files/wd/mrjob.zip as file:/tmp/hadoop-root/mapred/local/job_local16479360_0001_f291552e-31f6-4af3-b297-8dc64912f992/mrjob.zip\n",
            "  Localized file:/content/tmp/mrjob/tweetsSentiment.root.20220429.151723.431272/files/wd/setup-wrapper.sh as file:/tmp/hadoop-root/mapred/local/job_local16479360_0001_f0ab9512-4cb9-432b-a9fb-843e8cb4fc22/setup-wrapper.sh\n",
            "  Localized file:/content/tmp/mrjob/tweetsSentiment.root.20220429.151723.431272/files/wd/tweetsSentiment.py as file:/tmp/hadoop-root/mapred/local/job_local16479360_0001_4d29cfe6-73be-4fe7-8980-c6deab3f6265/tweetsSentiment.py\n",
            "  The url to track the job: http://localhost:8080/\n",
            "  Running job: job_local16479360_0001\n",
            "  OutputCommitter set in config null\n",
            "  OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
            "  File Output Committer Algorithm version is 2\n",
            "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "  Waiting for map tasks\n",
            "  Starting task: attempt_local16479360_0001_m_000000_0\n",
            "  File Output Committer Algorithm version is 2\n",
            "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "   Using ResourceCalculatorProcessTree : [ ]\n",
            "  Processing split: file:/content/tmp/mrjob/tweetsSentiment.root.20220429.151723.431272/files/tinyTweets.csv:0+3663\n",
            "  numReduceTasks: 1\n",
            "  (EQUATOR) 0 kvi 26214396(104857584)\n",
            "  mapreduce.task.io.sort.mb: 100\n",
            "  soft limit at 83886080\n",
            "  bufstart = 0; bufvoid = 104857600\n",
            "  kvstart = 26214396; length = 6553600\n",
            "  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "  PipeMapRed exec [/bin/sh, -ex, setup-wrapper.sh, python3, tweetsSentiment.py, --step-num=0, --mapper]\n",
            "  mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
            "  mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
            "  map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
            "  map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
            "  mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
            "  mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
            "  map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
            "  mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
            "  mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
            "  mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
            "  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
            "  user.name is deprecated. Instead, use mapreduce.job.user.name\n",
            "+ __mrjob_PWD=/content\n",
            "+ exec\n",
            "+ python3 -c import fcntl; fcntl.flock(9, fcntl.LOCK_EX)\n",
            "  R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "  R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "+ export PYTHONPATH=/content/mrjob.zip:/env/python\n",
            "+ exec\n",
            "+ cd /content\n",
            "+ python3 tweetsSentiment.py --step-num=0 --mapper\n",
            "  Job job_local16479360_0001 running in uber mode : false\n",
            "   map 0% reduce 0%\n",
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  Records R/W=51/1\n",
            "  MRErrorThread done\n",
            "  mapRedFinished\n",
            "  \n",
            "  Starting flush of map output\n",
            "  Spilling map output\n",
            "  bufstart = 0; bufend = 2102; bufvoid = 104857600\n",
            "  kvstart = 26214396(104857584); kvend = 26214180(104856720); length = 217/6553600\n",
            "  PipeMapRed exec [/bin/sh, -ex, setup-wrapper.sh, python3, tweetsSentiment.py, --step-num=0, --combiner]\n",
            "  mapred.skip.map.auto.incr.proc.count is deprecated. Instead, use mapreduce.map.skip.proc-count.auto-incr\n",
            "  R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "  R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "+ __mrjob_PWD=/content\n",
            "+ exec\n",
            "+ python3 -c import fcntl; fcntl.flock(9, fcntl.LOCK_EX)\n",
            "+ export PYTHONPATH=/content/mrjob.zip:/env/python\n",
            "+ exec\n",
            "+ cd /content\n",
            "+ python3 tweetsSentiment.py --step-num=0 --combiner\n",
            "  Records R/W=51/1 > sort\n",
            "   map 67% reduce 0%\n",
            "  Records R/W=51/1 > sort\n",
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  Records R/W=55/1\n",
            "Traceback (most recent call last):\n",
            "  File \"tweetsSentiment.py\", line 59, in <module>\n",
            "    tweetSentiment.run()\n",
            "  File \"/content/mrjob.zip/mrjob/job.py\", line 616, in run\n",
            "  File \"/content/mrjob.zip/mrjob/job.py\", line 678, in execute\n",
            "  File \"/content/mrjob.zip/mrjob/job.py\", line 780, in run_combiner\n",
            "  File \"/content/mrjob.zip/mrjob/job.py\", line 850, in combine_pairs\n",
            "  File \"/content/mrjob.zip/mrjob/job.py\", line 887, in _combine_or_reduce_pairs\n",
            "  File \"/content/mrjob.zip/mrjob/job.py\", line 971, in read_lines\n",
            "  File \"/content/mrjob.zip/mrjob/protocol.py\", line 95, in read\n",
            "  File \"/content/mrjob.zip/mrjob/protocol.py\", line 135, in _loads\n",
            "  File \"/usr/lib/python3.7/json/__init__.py\", line 348, in loads\n",
            "    return _default_decoder.decode(s)\n",
            "  File \"/usr/lib/python3.7/json/decoder.py\", line 337, in decode\n",
            "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
            "  File \"/usr/lib/python3.7/json/decoder.py\", line 355, in raw_decode\n",
            "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
            "json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1)\n",
            "  MRErrorThread done\n",
            "  PipeMapRed failed!\n",
            "java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
            "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
            "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
            "\tat org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)\n",
            "\tat org.apache.hadoop.mapred.Task$OldCombinerRunner.combine(Task.java:1844)\n",
            "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1665)\n",
            "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1506)\n",
            "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:473)\n",
            "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:350)\n",
            "\tat org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)\n",
            "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
            "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
            "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
            "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
            "  map task executor complete.\n",
            "  job_local16479360_0001\n",
            "java.lang.Exception: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
            "\tat org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)\n",
            "\tat org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)\n",
            "Caused by: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
            "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
            "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
            "\tat org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)\n",
            "\tat org.apache.hadoop.mapred.Task$OldCombinerRunner.combine(Task.java:1844)\n",
            "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1665)\n",
            "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1506)\n",
            "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:473)\n",
            "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:350)\n",
            "\tat org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)\n",
            "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
            "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
            "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
            "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
            "  Job job_local16479360_0001 failed with state FAILED due to: NA\n",
            "  Job not successful!\n",
            "  Streaming Command Failed!\n",
            "Counters: 18\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=3707\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=580674\n",
            "\t\tFILE: Number of bytes written=1216246\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tCombine input records=55\n",
            "\t\tCombine output records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tInput split bytes=140\n",
            "\t\tMap input records=51\n",
            "\t\tMap output bytes=2102\n",
            "\t\tMap output materialized bytes=0\n",
            "\t\tMap output records=55\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tSpilled Records=0\n",
            "\t\tTotal committed heap usage (bytes)=359661568\n",
            "Scanning logs for probable cause of failure...\n",
            "Can't fetch history log; missing job ID\n",
            "Can't fetch task logs; missing application ID\n",
            "Step 1 of 1 failed: Command '['/usr/local/hadoop-3.3.2/bin/hadoop', 'jar', '/usr/local/hadoop-3.3.2/share/hadoop/tools/lib/hadoop-streaming-3.3.2.jar', '-files', 'file:///content/tmp/mrjob/tweetsSentiment.root.20220429.151723.431272/files/wd/mrjob.zip#mrjob.zip,file:///content/tmp/mrjob/tweetsSentiment.root.20220429.151723.431272/files/wd/setup-wrapper.sh#setup-wrapper.sh,file:///content/tmp/mrjob/tweetsSentiment.root.20220429.151723.431272/files/wd/tweetsSentiment.py#tweetsSentiment.py', '-input', 'file:///content/tmp/mrjob/tweetsSentiment.root.20220429.151723.431272/files/tinyTweets.csv', '-output', 'file:///content/tmp/mrjob/tweetsSentiment.root.20220429.151723.431272/output', '-mapper', '/bin/sh -ex setup-wrapper.sh python3 tweetsSentiment.py --step-num=0 --mapper', '-combiner', '/bin/sh -ex setup-wrapper.sh python3 tweetsSentiment.py --step-num=0 --combiner', '-reducer', '/bin/sh -ex setup-wrapper.sh python3 tweetsSentiment.py --step-num=0 --reducer']' returned non-zero exit status 256.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "W12FRIvwontp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}